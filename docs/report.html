<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Project on Image Tagging Bias</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">
 <span class="menu-text">TEAM NAME</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./proposal.html">
 <span class="menu-text">Proposal</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./eda.html">
 <span class="menu-text">Exploratory data analysis</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./pre-registration.html">
 <span class="menu-text">Pre-registered analyses</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./presentation.html">
 <span class="menu-text">Presentation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./report.html" aria-current="page">
 <span class="menu-text">Report</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./appendicies.html">
 <span class="menu-text">Appendicies</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#data-description" id="toc-data-description" class="nav-link" data-scroll-target="#data-description">Data description</a></li>
  <li><a href="#data-analysis" id="toc-data-analysis" class="nav-link" data-scroll-target="#data-analysis">Data analysis</a></li>
  <li><a href="#evaluation-of-significance" id="toc-evaluation-of-significance" class="nav-link" data-scroll-target="#evaluation-of-significance">Evaluation of significance</a></li>
  <li><a href="#interpretation-and-conclusions" id="toc-interpretation-and-conclusions" class="nav-link" data-scroll-target="#interpretation-and-conclusions">Interpretation and conclusions</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#acknowledgments" id="toc-acknowledgments" class="nav-link" data-scroll-target="#acknowledgments">Acknowledgments</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Project on Image Tagging Bias</h1>
<p class="subtitle lead">Report</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In the age of AI and machine learning, vision-based cognitive services (CogS) have become integral to a wide array of applications, such as real-time security, social networks, and smartphone apps. As these services heavily rely on analyzing images of people and inferring emotions from facial expressions, it is crucial to examine their potential biases and ensure that they do not inadvertently perpetuate racial stereotypes.</p>
<p>We investigated if there is an inherent racial bias in image tagging emotion analyses services in their reading of emotions as compared to a real person reading emotion. We also wanted to know if this corroborates any previous research on the bias towards black individuals erroneously being perceived as angry or hostile through their expressions.</p>
<p>Upon analysis, we did not find any significant differences. However, we believe that the lack of significant findings may be due to issues with the dataset, warranting further exploration. Our report underscores the importance of rigorously examining potential biases in AI systems and highlights the need for more robust datasets and research methods to better understand and address these biases. While our current findings may not conclusively prove the existence of inherent biases in EAS, the study emphasizes the ongoing need for continuous evaluation and improvement of AI systems to ensure fairness, transparency, and accuracy in AI applications, ultimately contributing to a more ethical and inclusive technological landscape.</p>
</section>
<section id="data-description" class="level1">
<h1>Data description</h1>
<p>In our study, we analyzed two datasets to investigate the presence of inherent bias in emotion analysis services (EAS) taken from the Harvard Dataverse.</p>
<p>The person-data dataset contains human-generated data collected from participants in the US. Each row represents a different individual tasked with describing the facial emotion of a person in a photograph. The columns include information about the evaluator, such as the date and time of evaluation, the participant’s location (city and state), IP address, and demographic information (race and gender). Additionally, the dataset contains columns for the evaluator’s first and second choices of emotion to describe the person in the photo, the emotion they would not use, and the image identifier.</p>
<p>The EAS dataset comprises data generated by the emotion analysis services. Each row represents a unique image, and the columns contain the proportion of evaluators who classified the emotion expressed in the picture across seven different emotions. The first column provides the image identifier, while the subsequent columns display the proportions for the emotions Neutral (N), Happiness, Sadness, Surprise, Fear, Disgust, and Anger.</p>
<p>(Kyriakou, Kyriakos; Kleanthous, Styliani; Otterbarcher, Jahna; Papadopoulos, George, 2021, “Emotion Bias Dataset (EBD)”,&nbsp;<a href="https://doi.org/10.7910/DVN/8MW0RA" class="uri">https://doi.org/10.7910/DVN/8MW0RA</a>, Harvard Dataverse, V1, UNF:6:axjl4xEJLBvYutu0VQ0pMQ== [fileUNF] )<br>
<br>
Cleaned dataset contains information about emotions, race, and gender of 1208 individuals.</p>
<ul>
<li><p>Emotions of interest include SADNESS, NEUTRAL, ANGER, FEAR, and HAPPINESS.</p></li>
<li><p>Emotions are represented as percentages of the total emotional response, with values ranging from 0 to 1.</p></li>
<li><p>Race is represented as a categorical variable, with the category from White, Black, Latino, Asian.</p></li>
<li><p>Gender is also represented as a categorical variable, with the only category being Male and Female.<br>
<br>
<br>
</p></li>
</ul>
</section>
<section id="data-analysis" class="level1">
<h1>Data analysis</h1>
<div class="cell">

</div>
<p>Before continuing with the data analysis, it is important to highlight some potential issues in the data collection which may then lead to issues with the conclusions.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>    preds
     ANGER CONTEMPT DISGUST FEAR HAPPINESS NEUTRAL SADNESS SURPRISE
  A     51        5       4    0         2      91       1        0
  F      1        1       0   20        25       6      12       84
  HC     0        0       0    0       146       7       0        0
  HO     0        0       0    0       154       0       0        0
  N      0        0       0    0         1     591       4        1</code></pre>
</div>
</div>
<p>As you can see here, the emotion categories are slightly inconsistent in the dataset. The actual emotions in the row labels don’t exactly match up with the predicted emotions in the column labels. The options for actual are anger, fear, happy closed, happy open, and neutral. On the other hand, the option for the predicted are anger, contempt, disgust, fear, happiness, neutral, sadness, and surprise. This makes analyzing the data and making proper comparisons slightly more difficult and less straight forward.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 2
  race   `mean(accuracy)`
  &lt;chr&gt;             &lt;dbl&gt;
1 Asian             1    
2 Black             0.749
3 Latino            0.991
4 White             0.759</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     race    actual   n
1   Asian   NEUTRAL 109
2   Black   NEUTRAL 197
3   Black HAPPINESS 164
4   Black     ANGER  82
5   Black      FEAR  83
6  Latino   NEUTRAL 108
7   White   NEUTRAL 183
8   White HAPPINESS 143
9   White     ANGER  72
10  White      FEAR  66</code></pre>
</div>
</div>
<p>The tables above show another potential issue in the dataset. In the first table, you can see that the mean accuracy for the Asian and Latino race categories are suspiciously higher which requires further exploration. In the following table, one can observe that the reasoning for this is that for both categories, the only actual emotion option was “neutral”. This may create bias in the analysis, so for this reason we decided to only compare the Black and White race categories.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/race-heatmap-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In the heat maps above, each tile represents a unique combination of “predicted” and “actual” for a specific race (“Black” or “White”), and the color of the tile represents the count of that combination. The plot is divided into separate panels for each race. As we can see, the counts do not really show anything alarming. For Black, neutral is occasionally confused for neutral, and for both races anger is often confused with neutral. Fear is also confused with surprise for both races.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/emotion-counts-person-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This visualization uses a bar graph to show the distributions for emotion counts from the person data for black compared to white. There seems to fairly similar distributions between the two races, with slightly higher counts for surprise, happiness, and anger for black women compared to white. However, this does not raise much concern since two out of these three emotions are percieved as positive.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/eas-bar-graph-black-vs-white-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This visualization uses a bar graph to show the distributions for emotion counts from the EAS data for black compared to white. Again, there does not seem to be any alarming differences although we need to conduct tests to confirm this. There does not appear to be a significant difference in any of the emotion rating means when comparing black to white.</p>
<div class="cell">

</div>
</section>
<section id="evaluation-of-significance" class="level1">
<h1>Evaluation of significance</h1>
<p><strong>Hypothesis 1</strong></p>
<p>Null Hypothesis: There is no statistically significant difference between actual and predicted categories for race.</p>
<p><span class="math display">\[
H_0: p_1 - p_2 = 0
\]</span></p>
<p>Alternative Hypothesis: There is a statistically significant difference between actual and predicted categories for race.</p>
<p><span class="math display">\[
H_A: p_1 - p_2 \neq 0
\]</span></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>   category statisitcs     pvalue
1   NEUTRAL  4.7065990 0.09505501
2 HAPPINESS  0.9025027 0.34211153
3     ANGER  4.0391307 0.54379596
4      FEAR  7.9138975 0.24447953</code></pre>
</div>
</div>
<p>The output shows the results of the Chi-squared tests for the EAS data. Each row corresponds to a unique category in the actual column (‘NEUTRAL’, ‘HAPPINESS’, ‘ANGER’, ‘FEAR’), and the columns display the Chi-squared statistic and the associated p-value. All of the p-values are greater than 0.05, suggesting that there is not enough evidence to reject the null hypothesis of independence for any of the emotion categories. There is not enough evidence to support that there is a statistically significant difference between actual and predicted categories for race for any emotion in the EAS data.</p>
<p><strong>Hypothesis 2</strong></p>
<p>For our first hypothesis, we wanted to determine if there was a significantly higher proportion of “false positive” angry decisions made by the Emotion Analysis Service as compared to real people making the same decisions.</p>
<p>Null Hypothesis: There is not a significantly higher proportion of “false positives” for incorrect angry decisions made by the EAS for black men as compared to real people making the decision</p>
<p><span class="math display">\[
H_0: p_1 - p_2 = 0
\]</span></p>
<p>Alternative Hypothesis: There is a significantly higher proportion of “false positives” for incorrect angry decisions made by the EAS for black men as compared to real people making the decision.</p>
<p><span class="math display">\[
H_A: p_1 - p_2 \neq 0
\]</span> For this, we used a difference in proportions test in order to find out if there was a significant staitistical difference between the EAS and person type 1 errors. Our results was as shown below:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
    2-sample test for equality of proportions with continuity correction

data:  c(length(type1_eas), length(type1_person)) out of c(length(eas_data_clean), length(person_data_clean))
X-squared = 0.15476, df = 1, p-value = 0.694
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.6094210  0.3017287
sample estimates:
   prop 1    prop 2 
0.3846154 0.5384615 </code></pre>
</div>
</div>
<p>For our hypothesis test, we receive a p-value of 0.694, indicating that we fail to reject the null hypothesis. With a threshold of p &lt; 0.05, we can conclude that there is no significant difference in the type 1 errors of the EAS and people’s decisions when it comes to classifiying black men as angry.</p>
</section>
<section id="interpretation-and-conclusions" class="level1">
<h1>Interpretation and conclusions</h1>
<p>Based on the results obtained from the two-sample test, we observe a p-value of 0.694, exceeding the conventional significance threshold of 0.05. This suggests insufficient evidence to reject the null hypothesis, which posits that there is no inherent racial bias in Emotion Analysis Services’ (EAS) interpretation of emotions, compared to human evaluation. The 95% confidence interval for the difference in proportions is -0.5678590 to 0.4000268, which encompasses 0. This lends further weight to our conclusion, suggesting with 95% confidence that the true difference in proportions between the two groups falls within this interval, and therefore there is not a significant divergence in Type I error rates between the groups.</p>
<p>The Chi-squared tests performed for the second hypothesis further corroborate our conclusions. With p-values exceeding the alpha level of 0.05 for each emotion, we fail to reject the null hypothesis that there is no statistically significant difference between the actual and predicted categories for race across all emotions in the EAS data. This aligns with our earlier findings, suggesting a lack of inherent racial bias in EAS’s emotion interpretation.</p>
<p>However, it is paramount to acknowledge the potential limitations of our dataset, such as the under-representation of the Asian and Latino demographics and inconsistencies in the emotion variables. Such factors could potentially confound our analysis and merit further exploration.</p>
<p>Looking ahead, future work should aim to address these limitations. In particular, efforts should be directed towards compiling a more diverse and representative dataset. This would involve not only including more data from underrepresented racial groups but also ensuring that the range of emotions captured is comprehensive and consistently categorized. Furthermore, using a variety of statistical tests and machine learning models could provide a more robust analysis of potential biases. We also recommend performing longitudinal studies to track how the performance of these services evolves over time, as the algorithms learn and adapt.</p>
<p>While our findings do not conclusively indicate the presence of inherent racial bias in EAS, they underscore the importance of continuous evaluation and vigilance. This is crucial in ensuring that as these systems evolve, they do so in a manner that is fair, transparent, and accurate, contributing to an ethical and inclusive technological landscape.</p>
</section>
<section id="limitations" class="level1">
<h1>Limitations</h1>
<p>There are potential limitations based on the research design:</p>
<ol type="1">
<li>There is under-representation of the Asian and Latino demographics and inconsistencies in the emotion variables. This could potentially confound our analysis and merit further exploration.</li>
<li>Inconsistency in the emotion variables; the predicted and accurate options are not the same, potentially confounding our analysis.</li>
<li>The sample sizes (1207-1845 observations) used for the analysis may be too small to generalize conclusions about the population. This might lead to the sample that is not representative of the larger population.</li>
<li>The study relies heavily on the accuracy of the image tagging and emotion analysis services used. If these services are flawed, the results of the study may be inaccurate or unreliable.</li>
<li>The study is limited to the direct emotion variables included in the analysis. There may be other factors that influence emotion recognition that are not accounted for in the study, such as the lighting and picture quality.</li>
<li>Bias could exist, but could be the same for both the EAS and real decisions as the service could be trained on biased data which would also result in no statistical difference.</li>
</ol>
</section>
<section id="acknowledgments" class="level1">
<h1>Acknowledgments</h1>
<p>The heat-map was inspired by material from “Intro to ML - INFO 1998” taught by the Cornell Data Science project team.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>